{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n",
    "from torch.nn import functional as F\r\n",
    "from torch import optim\r\n",
    "\r\n",
    "import dlc_practical_prologue as prologue\r\n",
    "\r\n",
    "if torch.cuda.is_available():  \r\n",
    "  dev=\"cuda:0\"\r\n",
    "  device = torch.device(dev) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = prologue.generate_pair_sets(1000)\r\n",
    "\r\n",
    "train_input=pairs[0].cuda()\r\n",
    "train_target=pairs[1].cuda()\r\n",
    "train_classes=pairs[2].cuda()\r\n",
    "test_input=pairs[3].cuda()\r\n",
    "test_target=pairs[4].cuda()\r\n",
    "test_classes=pairs[5].cuda()\r\n",
    "\r\n",
    "train_classes1=prologue.convert_to_one_hot_labels(train_input,train_classes[:,0])\r\n",
    "train_classes2=prologue.convert_to_one_hot_labels(train_input,train_classes[:,1])\r\n",
    "train_classes_hot=torch.cat((train_classes1,train_classes2),1)\r\n",
    "\r\n",
    "train_classes1=prologue.convert_to_one_hot_labels(train_input,train_classes[:,0])\r\n",
    "train_classes2=prologue.convert_to_one_hot_labels(train_input,train_classes[:,1])\r\n",
    "test_classes_hot=torch.cat((train_classes1,train_classes2),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n         0., 0.], device='cuda:0'),\n tensor(0, device='cuda:0'))"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_classes_hot=torch.cat((train_classes1,train_classes2),1)\r\n",
    "train_classes_hot[1], train_target[1]\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "class MLPAux(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.fc1 = nn.Linear(392, 500)\r\n",
    "        self.fc2 = nn.Linear(500, 20)\r\n",
    "        self.fc3 = nn.Linear(20, 2)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = F.relu(self.fc1(x))\r\n",
    "        y = self.fc2(x)\r\n",
    "        x = F.relu(self.fc2(x))\r\n",
    "        x = self.fc3(x)\r\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, train_classes):\r\n",
    "    criterion  = nn.CrossEntropyLoss()\r\n",
    "    criterion2 = nn.BCEWithLogitsLoss()\r\n",
    "    optimizer  = optim.SGD(model.parameters(), lr = 1e-3)\r\n",
    "    nb_epochs  = 100\r\n",
    "    mini_batch_size= 100\r\n",
    "\r\n",
    "    for e in range(nb_epochs):\r\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\r\n",
    "            output, output2 = model(train_input.narrow(0, b, mini_batch_size).view((mini_batch_size,-1)))\r\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size)) + criterion2(output2, train_classes.narrow(0, b, mini_batch_size))\r\n",
    "            optimizer.zero_grad()\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, data_input, data_target):\r\n",
    "\r\n",
    "    nb_data_errors = 0\r\n",
    "    mini_batch_size= 100\r\n",
    "    for b in range(0, data_input.size(0), mini_batch_size):\r\n",
    "        output, output2 = model(data_input.narrow(0, b, mini_batch_size).view((mini_batch_size,-1)))\r\n",
    "        _, predicted_classes = torch.max(output, 1)\r\n",
    "        for k in range(mini_batch_size):\r\n",
    "            if data_target[b + k] != predicted_classes[k]:\r\n",
    "                nb_data_errors = nb_data_errors + 1\r\n",
    "\r\n",
    "    return nb_data_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_error 2.30% test_error 22.50%\n",
      "train_error 7.00% test_error 27.40%\n",
      "train_error 3.20% test_error 21.90%\n",
      "train_error 1.20% test_error 21.50%\n",
      "train_error 2.90% test_error 26.60%\n"
     ]
    }
   ],
   "source": [
    "train_E=[]\r\n",
    "test_E=[]\r\n",
    "\r\n",
    "for k in range(5):\r\n",
    "    model=MLPAux().cuda()\r\n",
    "    train_model(model,train_input,train_target,train_classes_hot)\r\n",
    "    train_E.append(compute_nb_errors(model, train_input, train_target) / train_input.size(0) * 100)\r\n",
    "    test_E.append(compute_nb_errors(model, test_input, test_target) / test_input.size(0) * 100)\r\n",
    "    print('train_error {:.02f}% test_error {:.02f}%'.format(train_E[-1],test_E[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python385jvsc74a57bd097ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}